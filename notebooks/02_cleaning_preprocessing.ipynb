{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc6ffd1b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c061f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from src.preprocess import basic_clean\n",
    "\n",
    "df_posts_clean = basic_clean(df_posts, text_cols=(\"title\",\"body\"))\n",
    "df_comments_clean = basic_clean(df_comments, text_cols=(\"body\",))\n",
    "df_posts_clean.shape, df_comments_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b61968",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load zero-shot classification pipeline\n",
    "clf = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "labels = [\"relevant to bugs/pack quality/issues\", \"not relevant (showcase/story)\"]\n",
    "\n",
    "def combine_text(row):\n",
    "    return \" \".join([str(row.get(\"title\",\"\")), str(row.get(\"body\",\"\"))]).strip()\n",
    "\n",
    "# Build text column\n",
    "df[\"text\"] = df.apply(combine_text, axis=1)\n",
    "\n",
    "# Apply classifier\n",
    "zs = clf(df[\"text\"].tolist(), candidate_labels=labels, multi_label=False)\n",
    "\n",
    "df[\"zs_label\"] = [res[\"labels\"][0] for res in zs]\n",
    "df[\"zs_score\"] = [res[\"scores\"][0] for res in zs]\n",
    "\n",
    "# Keep only relevant ones above threshold\n",
    "df_filtered = df[(df[\"zs_label\"] == \"relevant to bugs/pack quality/issues\") & (df[\"zs_score\"] >= 0.75)]\n",
    "\n",
    "print(f\"Zero-shot kept {len(df_filtered)}/{len(df)} posts ({len(df_filtered)/len(df):.1%}).\")\n",
    "\n",
    "# Save to processed\n",
    "df_filtered.to_csv(\"../data/processed/reddit_sims4_filtered.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c9c23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def collect_reddit_posts(\n",
    "    client_id,\n",
    "    client_secret,\n",
    "    user_agent,\n",
    "    subreddit_name=\"Sims4\",\n",
    "    limit=500,\n",
    "    time_filter=\"year\",\n",
    "    mode=\"top\"\n",
    "):\n",
    "    reddit = praw.Reddit(client_id=client_id, client_secret=client_secret, user_agent=user_agent)\n",
    "    sr = reddit.subreddit(subreddit_name)\n",
    "\n",
    "    if mode == \"top\":\n",
    "        stream = sr.top(limit=limit, time_filter=time_filter)\n",
    "    elif mode == \"new\":\n",
    "        stream = sr.new(limit=limit)\n",
    "    elif mode == \"hot\":\n",
    "        stream = sr.hot(limit=limit)\n",
    "    else:\n",
    "        raise ValueError(\"mode must be one of {'top','new','hot'}\")\n",
    "\n",
    "    rows = []\n",
    "    for post in stream:\n",
    "        rows.append({\n",
    "            \"id\": post.id,\n",
    "            \"created_utc\": post.created_utc,  # raw unix timestamp\n",
    "            \"created_date\": datetime.utcfromtimestamp(post.created_utc),  # human-readable\n",
    "            \"author\": str(getattr(post.author, \"name\", None)),\n",
    "            \"title\": post.title or \"\",\n",
    "            \"body\": post.selftext or \"\",\n",
    "            \"score\": post.score,\n",
    "            \"num_comments\": post.num_comments,\n",
    "            \"permalink\": f\"https://reddit.com{post.permalink}\",\n",
    "            \"subreddit\": subreddit_name\n",
    "        })\n",
    "    return pd.DataFrame(rows)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
